const content = `--[[
  Move job from active to a finished status (completed o failed)
  A job can only be moved to completed if it was active.
  The job must be locked before it can be moved to a finished status,
  and the lock must be released in this script.
     Input:
      KEYS[1] wait key
      KEYS[2] active key
      KEYS[3] prioritized key
      KEYS[4] stream events key
      KEYS[5] stalled key
      -- Rate limiting
      KEYS[6] rate limiter key
      KEYS[7] delayed key
      KEYS[8] paused key
      KEYS[9] meta key
      KEYS[10] pc priority counter
      KEYS[11] completed/failed key
      KEYS[12] jobId key
      KEYS[13] metrics key
      KEYS[14] marker key
      ARGV[1]  jobId
      ARGV[2]  timestamp
      ARGV[3]  msg property
      ARGV[4]  return value / failed reason
      ARGV[5]  target (completed/failed)
      ARGV[6]  fetch next?
      ARGV[7]  keys prefix
      ARGV[8]  opts
      ARGV[9]  job fields to update
     Output:
      0 OK
      -1 Missing key.
      -2 Missing lock.
      -3 Job not in active set
      -4 Job has pending dependencies
      -6 Lock is not owned by this client
     Events:
      'completed/failed'
]]
local rcall = redis.call
local waitKey = KEYS[1]
local activeKey = KEYS[2]
local prioritizedKey = KEYS[3]
local eventStreamKey = KEYS[4]
local stalledKey = KEYS[5]
local finishedKey = KEYS[11]
local jobIdKey = KEYS[12]
local metaKey = KEYS[9]
local timestamp = ARGV[2]
local prefixKey = ARGV[7]
-- Includes
--[[
  Functions to collect metrics based on a current and previous count of jobs.
  Granualarity is fixed at 1 minute.
]] 
--[[
  Function to loop in batches.
  Just a bit of warning, some commands as ZREM
  could receive a maximum of 7000 parameters per call.
]]
local function batches(n, batchSize)
  local i = 0
  return function()
    local from = i * batchSize + 1
    i = i + 1
    if (from <= n) then
      local to = math.min(from + batchSize - 1, n)
      return from, to
    end
  end
end
local function collectMetrics(metaKey, dataPointsList, maxDataPoints,
                                 timestamp)
    -- Increment current count
    local count = rcall("HINCRBY", metaKey, "count", 1) - 1
    -- Compute how many data points we need to add to the list, N.
    local prevTS = rcall("HGET", metaKey, "prevTS")
    if not prevTS then
        -- If prevTS is nil, set it to the current timestamp
        rcall("HSET", metaKey, "prevTS", timestamp, "prevCount", 0)
        return
    end
    local N = math.min(math.floor(timestamp / 60000) - math.floor(prevTS / 60000), tonumber(maxDataPoints))
    if N > 0 then
        local delta = count - rcall("HGET", metaKey, "prevCount")
        -- If N > 1, add N-1 zeros to the list
        if N > 1 then
            local points = {}
            points[1] = delta
            for i = 2, N do
                points[i] = 0
            end
            for from, to in batches(#points, 7000) do
                rcall("LPUSH", dataPointsList, unpack(points, from, to))
            end
        else
            -- LPUSH delta to the list
            rcall("LPUSH", dataPointsList, delta)
        end
        -- LTRIM to keep list to its max size
        rcall("LTRIM", dataPointsList, 0, maxDataPoints - 1)
        -- update prev count with current count
        rcall("HSET", metaKey, "prevCount", count, "prevTS", timestamp)
    end
end
--[[
  Functions to destructure job key.
  Just a bit of warning, these functions may be a bit slow and affect performance significantly.
]]
local getJobIdFromKey = function (jobKey)
  return string.match(jobKey, ".*:(.*)")
end
local getJobKeyPrefix = function (jobKey, jobId)
  return string.sub(jobKey, 0, #jobKey - #jobId)
end
--[[
  Function to get current rate limit ttl.
]]
local function getRateLimitTTL(maxJobs, rateLimiterKey)
  if maxJobs and maxJobs <= tonumber(rcall("GET", rateLimiterKey) or 0) then
    local pttl = rcall("PTTL", rateLimiterKey)
    if pttl == 0 then
      rcall("DEL", rateLimiterKey)
    end
    if pttl > 0 then
      return pttl
    end
  end
  return 0
end
--[[
  Function to check for the meta.paused key to decide if we are paused or not
  (since an empty list and !EXISTS are not really the same).
]]
local function getTargetQueueList(queueMetaKey, activeKey, waitKey, pausedKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return pausedKey, true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      if activeCount >= tonumber(queueAttributes[2]) then
        return waitKey, true
      else
        return waitKey, false
      end
    end
  end
  return waitKey, false
end
--[[
  Function to recursively move from waitingChildren to failed.
]]
-- Includes
--[[
  Validate and move parent to active if needed.
]]
-- Includes
--[[
  Add delay marker if needed.
]]
-- Includes
--[[
  Function to return the next delayed job timestamp.
]]
local function getNextDelayedTimestamp(delayedKey)
  local result = rcall("ZRANGE", delayedKey, 0, 0, "WITHSCORES")
  if #result then
    local nextTimestamp = tonumber(result[2])
    if nextTimestamp ~= nil then 
      return nextTimestamp / 0x1000
    end
  end
end
local function addDelayMarkerIfNeeded(markerKey, delayedKey)
  local nextTimestamp = getNextDelayedTimestamp(delayedKey)
  if nextTimestamp ~= nil then
    -- Replace the score of the marker with the newest known
    -- next timestamp.
    rcall("ZADD", markerKey, nextTimestamp, "1")
  end
end
--[[
  Function to add job in target list and add marker if needed.
]]
-- Includes
--[[
  Add marker if needed when a job is available.
]]
local function addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
  if not isPausedOrMaxed then
    rcall("ZADD", markerKey, 0, "0")
  end  
end
local function addJobInTargetList(targetKey, markerKey, pushCmd, isPausedOrMaxed, jobId)
  rcall(pushCmd, targetKey, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to add job considering priority.
]]
-- Includes
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId, priorityCounterKey,
  isPausedOrMaxed)
  local prioCounter = rcall("INCR", priorityCounterKey)
  local score = priority * 0x100000000 + prioCounter % 0x100000000
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
--[[
  Function to check if queue is paused or maxed
  (since an empty list and !EXISTS are not really the same).
]]
local function isQueuePausedOrMaxed(queueMetaKey, activeKey)
  local queueAttributes = rcall("HMGET", queueMetaKey, "paused", "concurrency")
  if queueAttributes[1] then
    return true
  else
    if queueAttributes[2] then
      local activeCount = rcall("LLEN", activeKey)
      return activeCount >= tonumber(queueAttributes[2])
    end
  end
  return false
end
local function moveParentToWaitIfNeeded(parentQueueKey, parentDependenciesKey,
                                        parentKey, parentId, timestamp)
    local isParentActive = rcall("ZSCORE",
                                 parentQueueKey .. ":waiting-children", parentId)
    if rcall("SCARD", parentDependenciesKey) == 0 and isParentActive then
        rcall("ZREM", parentQueueKey .. ":waiting-children", parentId)
        local parentWaitKey = parentQueueKey .. ":wait"
        local parentPausedKey = parentQueueKey .. ":paused"
        local parentActiveKey = parentQueueKey .. ":active"
        local parentMetaKey = parentQueueKey .. ":meta"
        local parentMarkerKey = parentQueueKey .. ":marker"
        local jobAttributes = rcall("HMGET", parentKey, "priority", "delay")
        local priority = tonumber(jobAttributes[1]) or 0
        local delay = tonumber(jobAttributes[2]) or 0
        if delay > 0 then
            local delayedTimestamp = tonumber(timestamp) + delay
            local score = delayedTimestamp * 0x1000
            local parentDelayedKey = parentQueueKey .. ":delayed"
            rcall("ZADD", parentDelayedKey, score, parentId)
            rcall("XADD", parentQueueKey .. ":events", "*", "event", "delayed",
                  "jobId", parentId, "delay", delayedTimestamp)
            addDelayMarkerIfNeeded(parentMarkerKey, parentDelayedKey)
        else
            if priority == 0 then
                local parentTarget, isParentPausedOrMaxed =
                    getTargetQueueList(parentMetaKey, parentActiveKey, parentWaitKey,
                                       parentPausedKey)
                addJobInTargetList(parentTarget, parentMarkerKey, "RPUSH", isParentPausedOrMaxed,
                    parentId)
            else
                local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
                addJobWithPriority(parentMarkerKey,
                                   parentQueueKey .. ":prioritized", priority,
                                   parentId, parentQueueKey .. ":pc", isPausedOrMaxed)
            end
            rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting",
                  "jobId", parentId, "prev", "waiting-children")
        end
    end
end
--[[
  Function to remove deduplication key if needed.
]]
local function removeDeduplicationKeyIfNeeded(prefixKey, deduplicationId)
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    local pttl = rcall("PTTL", deduplicationKey)
    if pttl == 0 or pttl == -1 then
      rcall("DEL", deduplicationKey)
    end
  end
end
--[[
  Functions to remove jobs when removeOnFail option is provided.
]]
-- Includes
--[[
  Function to remove job.
]]
-- Includes
--[[
  Function to remove deduplication key.
]]
local function removeDeduplicationKey(prefixKey, jobKey)
  local deduplicationId = rcall("HGET", jobKey, "deid")
  if deduplicationId then
    local deduplicationKey = prefixKey .. "de:" .. deduplicationId
    rcall("DEL", deduplicationKey)
  end
end
--[[
  Function to remove job keys.
]]
local function removeJobKeys(jobKey)
  return rcall("DEL", jobKey, jobKey .. ':logs',
    jobKey .. ':dependencies', jobKey .. ':processed', jobKey .. ':failed')
end
--[[
  Check if this job has a parent. If so we will just remove it from
  the parent child list, but if it is the last child we should move the parent to "wait/paused"
  which requires code from "moveToFinished"
]]
-- Includes
local function moveParentToWait(parentPrefix, parentId, emitEvent)
  local parentTarget, isPausedOrMaxed = getTargetQueueList(parentPrefix .. "meta", parentPrefix .. "active",
    parentPrefix .. "wait", parentPrefix .. "paused")
  addJobInTargetList(parentTarget, parentPrefix .. "marker", "RPUSH", isPausedOrMaxed, parentId)
  if emitEvent then
    local parentEventStream = parentPrefix .. "events"
    rcall("XADD", parentEventStream, "*", "event", "waiting", "jobId", parentId, "prev", "waiting-children")
  end
end
local function removeParentDependencyKey(jobKey, hard, parentKey, baseKey, debounceId)
  if parentKey then
    local parentDependenciesKey = parentKey .. ":dependencies"
    local result = rcall("SREM", parentDependenciesKey, jobKey)
    if result > 0 then
      local pendingDependencies = rcall("SCARD", parentDependenciesKey)
      if pendingDependencies == 0 then
        local parentId = getJobIdFromKey(parentKey)
        local parentPrefix = getJobKeyPrefix(parentKey, parentId)
        local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
        if numRemovedElements == 1 then
          if hard then -- remove parent in same queue
            if parentPrefix == baseKey then
              removeParentDependencyKey(parentKey, hard, nil, baseKey, nil)
              removeJobKeys(parentKey)
              if debounceId then
                rcall("DEL", parentPrefix .. "de:" .. debounceId)
              end
            else
              moveParentToWait(parentPrefix, parentId)
            end
          else
            moveParentToWait(parentPrefix, parentId, true)
          end
        end
      end
      return true
    end
  else
    local parentAttributes = rcall("HMGET", jobKey, "parentKey", "deid")
    local missedParentKey = parentAttributes[1]
    if( (type(missedParentKey) == "string") and missedParentKey ~= ""
      and (rcall("EXISTS", missedParentKey) == 1)) then
      local parentDependenciesKey = missedParentKey .. ":dependencies"
      local result = rcall("SREM", parentDependenciesKey, jobKey)
      if result > 0 then
        local pendingDependencies = rcall("SCARD", parentDependenciesKey)
        if pendingDependencies == 0 then
          local parentId = getJobIdFromKey(missedParentKey)
          local parentPrefix = getJobKeyPrefix(missedParentKey, parentId)
          local numRemovedElements = rcall("ZREM", parentPrefix .. "waiting-children", parentId)
          if numRemovedElements == 1 then
            if hard then
              if parentPrefix == baseKey then
                removeParentDependencyKey(missedParentKey, hard, nil, baseKey, nil)
                removeJobKeys(missedParentKey)
                if parentAttributes[2] then
                  rcall("DEL", parentPrefix .. "de:" .. parentAttributes[2])
                end
              else
                moveParentToWait(parentPrefix, parentId)
              end
            else
              moveParentToWait(parentPrefix, parentId, true)
            end
          end
        end
        return true
      end
    end
  end
  return false
end
local function removeJob(jobId, hard, baseKey, shouldRemoveDeduplicationKey)
  local jobKey = baseKey .. jobId
  removeParentDependencyKey(jobKey, hard, nil, baseKey)
  if shouldRemoveDeduplicationKey then
    removeDeduplicationKey(baseKey, jobKey)
  end
  removeJobKeys(jobKey)
end
--[[
  Functions to remove jobs by max age.
]]
-- Includes
local function removeJobsByMaxAge(timestamp, maxAge, targetSet, prefix,
  shouldRemoveDebounceKey)
  local start = timestamp - maxAge * 1000
  local jobIds = rcall("ZREVRANGEBYSCORE", targetSet, start, "-inf")
  for i, jobId in ipairs(jobIds) do
    removeJob(jobId, false, prefix, false --[[remove debounce key]])
  end
  rcall("ZREMRANGEBYSCORE", targetSet, "-inf", start)
end
--[[
  Functions to remove jobs by max count.
]]
-- Includes
local function removeJobsByMaxCount(maxCount, targetSet, prefix)
  local start = maxCount
  local jobIds = rcall("ZREVRANGE", targetSet, start, -1)
  for i, jobId in ipairs(jobIds) do
    removeJob(jobId, false, prefix, false --[[remove debounce key]])
  end
  rcall("ZREMRANGEBYRANK", targetSet, 0, -(maxCount + 1))
end
local function removeJobsOnFail(queueKeyPrefix, failedKey, jobId, opts, timestamp)
  local removeOnFailType = type(opts["removeOnFail"])
  if removeOnFailType == "number" then
    removeJobsByMaxCount(opts["removeOnFail"],
                        failedKey, queueKeyPrefix)
  elseif removeOnFailType == "boolean" then
    if opts["removeOnFail"] then
      removeJob(jobId, false, queueKeyPrefix,
                false --[[remove debounce key]])
      rcall("ZREM", failedKey, jobId)
    end
  elseif removeOnFailType ~= "nil" then
    local maxAge = opts["removeOnFail"]["age"]
    local maxCount = opts["removeOnFail"]["count"]
    if maxAge ~= nil then
      removeJobsByMaxAge(timestamp, maxAge,
                        failedKey, queueKeyPrefix)
    end
    if maxCount ~= nil and maxCount > 0 then
      removeJobsByMaxCount(maxCount, failedKey,
                            queueKeyPrefix)
    end
  end 
end
local function moveParentFromWaitingChildrenToFailed( parentQueueKey, parentKey, parentId, jobIdKey, timestamp)
  if rcall("ZREM", parentQueueKey .. ":waiting-children", parentId) == 1 then
    local parentQueuePrefix = parentQueueKey .. ":"
    local parentFailedKey = parentQueueKey .. ":failed"
    rcall("ZADD", parentFailedKey, timestamp, parentId)
    local failedReason = "child " .. jobIdKey .. " failed"
    rcall("HMSET", parentKey, "failedReason", failedReason, "finishedOn", timestamp)
    rcall("XADD", parentQueueKey .. ":events", "*", "event", "failed", "jobId", parentId, "failedReason",
      failedReason, "prev", "waiting-children")
    local jobAttributes = rcall("HMGET", parentKey, "parent", "deid", "opts")
    removeDeduplicationKeyIfNeeded(parentQueueKey .. ":", jobAttributes[2])
    if jobAttributes[1] then
      local parentData = cjson.decode(jobAttributes[1])
      if parentData['fpof'] then
        moveParentFromWaitingChildrenToFailed(
          parentData['queueKey'],
          parentData['queueKey'] .. ':' .. parentData['id'],
          parentData['id'],
          parentKey,
          timestamp
        )
      elseif parentData['idof'] or parentData['rdof'] then
        local grandParentKey = parentData['queueKey'] .. ':' .. parentData['id']
        local grandParentDependenciesSet = grandParentKey .. ":dependencies"
        if rcall("SREM", grandParentDependenciesSet, parentKey) == 1 then
          moveParentToWaitIfNeeded(parentData['queueKey'], grandParentDependenciesSet,
            grandParentKey, parentData['id'], timestamp)
          if parentData['idof'] then
            local grandParentFailedSet = grandParentKey .. ":failed"
            rcall("HSET", grandParentFailedSet, parentKey, failedReason)
          end
        end
      end
    end
    local parentRawOpts = jobAttributes[3]
    local parentOpts = cjson.decode(parentRawOpts)
    removeJobsOnFail(parentQueuePrefix, parentFailedKey, parentId, parentOpts, timestamp)
  end
end
local function removeLock(jobKey, stalledKey, token, jobId)
  if token ~= "0" then
    local lockKey = jobKey .. ':lock'
    local lockToken = rcall("GET", lockKey)
    if lockToken == token then
      rcall("DEL", lockKey)
      rcall("SREM", stalledKey, jobId)
    else
      if lockToken then
        -- Lock exists but token does not match
        return -6
      else
        -- Lock is missing completely
        return -2
      end
    end
  end
  return 0
end
--[[
  Function to trim events, default 10000.
]]
-- Includes
--[[
  Function to get max events value or set by default 10000.
]]
local function getOrSetMaxEvents(metaKey)
    local maxEvents = rcall("HGET", metaKey, "opts.maxLenEvents")
    if not maxEvents then
        maxEvents = 10000
        rcall("HSET", metaKey, "opts.maxLenEvents", maxEvents)
    end
    return maxEvents
end
local function trimEvents(metaKey, eventStreamKey)
  local maxEvents = getOrSetMaxEvents(metaKey)
  if maxEvents ~= false then
    rcall("XTRIM", eventStreamKey, "MAXLEN", "~", maxEvents)
  else
    rcall("XTRIM", eventStreamKey, "MAXLEN", "~", 10000)
  end
end
--[[
  Function to update a bunch of fields in a job.
]]
local function updateJobFields(jobKey, msgpackedFields)
    if msgpackedFields and #msgpackedFields > 0 then
        local fieldsToUpdate = cmsgpack.unpack(msgpackedFields)
        if fieldsToUpdate then
            redis.call("HMSET", jobKey, unpack(fieldsToUpdate))
        end
    end
end
--[[
  Function to decrease group concurrency.
  Returns true if group is removed from maxed.
]]
-- Includes
--[[
  Promote a maxed group (if any) so that it is not maxed anymore
]]
-- Includes
-- Includes
local function isGroupRateLimited(groupKey)
  local groupRateLimitKey = groupKey .. ':limit'
  local jobCounter = tonumber(rcall("GET", groupRateLimitKey))
  return jobCounter and jobCounter >= 999999
end
--[[
  Reinsert the group with the highest score so that it is moved to the last position
]]
local function reinsertGroupIfNeeded(groupKey, groupsKey, groupId)
  if rcall("LLEN", groupKey) > 0 or rcall("ZCARD", groupKey .. ":p") > 0 then
    local highscore = rcall("ZREVRANGE", groupsKey, 0, 0, "withscores")[2] or 0
    -- Note, this mechanism could keep increasing the score indefinetely.
    -- Score can represent 2^53 integers, so approximatelly 285 years adding 1M jobs/second
    -- before it starts misbehaving.
    rcall("ZADD", groupsKey, highscore + 1, groupId)
    return true
  else
    rcall("HDEL", groupsKey .. ":pc", groupId)
    return false
  end
end
local function reinsertGroupIfNotRateLimitedOrPaused(prefixKey, groupId)
  if rcall("ZSCORE", prefixKey .. "groups:paused", groupId) == false then
    local groupKey = prefixKey .. 'groups:' .. groupId
    if not isGroupRateLimited(groupKey) then
      local groupsKey = prefixKey .. 'groups'
      return reinsertGroupIfNeeded(groupKey, groupsKey, groupId)
    end
  end
end
local function promoteMaxedGroup(prefixKey, markerKey, paused, groupId)
    if rcall("ZREM", prefixKey .. "groups:max", groupId) > 0 then
        local groupsKey = prefixKey .. 'groups'
        if reinsertGroupIfNotRateLimitedOrPaused(prefixKey, groupId) then
            addBaseMarkerIfNeeded(markerKey, paused)
        end
    end
end
local function isGroupMaxed(prefixKey, groupId)
  return rcall("ZSCORE", prefixKey .. "groups:max", groupId) ~= false
end
local function decreaseGroupConcurrency(prefixKey, markerKey, paused, groupId, maxConcurrency)
    local activeCountKey = prefixKey .. "groups:active:count"
    local activeCount = rcall("HGET", activeCountKey, groupId)
    if activeCount then
        local count = rcall("HINCRBY", activeCountKey, groupId, -1)
        if count <= 0 then rcall("HDEL", activeCountKey, groupId) end
        local localConcurrency = rcall("HGET", prefixKey .. "groups:concurrency", groupId)
        -- We use maxConcurrency, in case the user decides to change it (lower it),
        -- we need to check it here so that we keep the group in active if necessary.
        if count < tonumber(localConcurrency or maxConcurrency) and
            isGroupMaxed(prefixKey, groupId) then
            promoteMaxedGroup(prefixKey, markerKey, paused, groupId)
            return true
        end
    end
    return false
end
--[[
    Fetches the next job to be processed and locks it atomically for the specified worker.
    If there are jobs but they are delayed or rate limit, this function will return the next
    delayed or rate limited timestamp so that the worker can sleep until that time before
    asking for a new job again.
]]
-- Includes
--[[
  Function to move job from prioritized state to active.
]]
local function moveJobFromPrioritizedToActive(priorityKey, activeKey, priorityCounterKey, groupId)
  local prioritizedJob = rcall("ZPOPMIN", priorityKey)
  if #prioritizedJob > 0 then
    rcall("LPUSH", activeKey, prioritizedJob[1])
    return prioritizedJob[1]
  else
    if groupId then
      rcall("HDEL", priorityCounterKey, groupId)
    else
      rcall("DEL", priorityCounterKey)
    end
  end
end
-- Includes
local function increaseGroupConcurrency(groupsKey, groupId, maxConcurrency, timestamp)
  local count = rcall("HINCRBY", groupsKey .. ':active:count', groupId, 1)
  local localConcurrency = rcall("HGET", groupsKey .. ":concurrency", groupId)
  if count >= tonumber(localConcurrency or maxConcurrency) then
    rcall("ZADD", groupsKey .. ':max', timestamp, groupId)
    rcall("ZREM", groupsKey, groupId)
    return true
  end
end
local function rateLimitGroup(prefixKey, groupId, maxRate, rateDuration,
                              timestamp)
    if maxRate then
        local groupsKey = prefixKey .. 'groups'
        local groupKey = groupsKey .. ':' .. groupId
        local groupRateLimitKey = groupKey .. ':limit'
        -- Update limit key for this group, if rate-limited move the group to the rate limited zset
        local jobCounter = tonumber(rcall("INCR", groupRateLimitKey))
        if jobCounter == 1 then
            rcall("PEXPIRE", groupRateLimitKey, rateDuration)
        end
        -- -- check if rate limit hit
        if jobCounter >= maxRate then
            if jobCounter < 999999 then
                -- Set magic number 999999 to mark this group as rate limited
                -- use INCRBY as SET would clean the EXPIRE on the key.
                rcall("INCRBY", groupRateLimitKey, 999999)
            end
            -- Since this group is rate limited, remove it from the groupsKey and
            -- add it to the limit set.
            rcall("ZREM", groupsKey, groupId)
            local groupsRateLimitKey = prefixKey .. 'groups:limit'
            local nextTimestamp = timestamp + rateDuration
            rcall("ZADD", groupsRateLimitKey, nextTimestamp, groupId)
            return true
        end
    end
    return false
end
-- TODO: We are missing the fact that if we get rate limited in "moveToActive" or "moveToFinished" we need
-- to also return the next TTL, so basically taking the min(promoted-TTL, newRateLimitedTTL)
local function moveJobToActiveFromGroup(prefixKey, activeKey, groupMaxConcurrency,
  groupLimit, groupLimitDuration, timestamp)
  local groupsKey = prefixKey .. 'groups'
  local jobId
  -- Try to fetch next group's jobs
  local groupIds = rcall("ZPOPMIN", groupsKey)
  if #groupIds > 0 then
    local groupId = groupIds[1]
    local groupKey = groupsKey .. ':' .. groupId
    jobId = rcall("RPOPLPUSH", groupKey, activeKey)
    if not jobId then
      jobId = moveJobFromPrioritizedToActive(groupKey .. ":p", activeKey, groupKey .. ":pc", groupId)
    end
    -- Handle maxGroupConcurrency
    if groupMaxConcurrency and jobId then
      if increaseGroupConcurrency(groupsKey, groupId, groupMaxConcurrency, timestamp) then
        return jobId
      end
    end
    if groupLimit and jobId then
      if rateLimitGroup(prefixKey, groupId, groupLimit, groupLimitDuration, timestamp) then
        return jobId
      end
    end
    reinsertGroupIfNeeded(groupKey, groupsKey, groupId)
    rcall("SET", prefixKey .. 'groups-lid', groupId)
  end
  return jobId
end
-- Includes
local function prepareJobForProcessing(keyPrefix, rateLimiterKey,
                                       eventStreamKey, jobId, processedOn,
                                       maxJobs, markerKey, options, rateLimitedNextTtl)
    local token = options['token']
    local lockDuration = options['lockDuration']
    local jobKey = keyPrefix .. jobId
    if maxJobs then
        -- Check if we need to perform global rate limiting
        local jobCounter = tonumber(rcall("INCR", rateLimiterKey))
        if jobCounter == 1 then
            local limiterDuration = options['limiter'] and
                                        options['limiter']['duration']
            local integerDuration = math.floor(math.abs(limiterDuration))
            rcall("PEXPIRE", rateLimiterKey, integerDuration)
        end
    end
    local lockKey = jobKey .. ':lock'
    rcall("SET", lockKey, token, "PX", lockDuration)
    local optionalValues = {}
    if options['name'] then
        -- Set "processedBy" field to the worker name
        table.insert(optionalValues, "pb")
        table.insert(optionalValues, opts['name'])
    end
    rcall("XADD", eventStreamKey, "*", "event", "active", "jobId", jobId,
          "prev", "waiting")
    rcall("HMSET", jobKey, "processedOn", processedOn, unpack(optionalValues))
    rcall("HINCRBY", jobKey, "ats", 1)
    -- This is a bit wrong actually, the queue could have jobs that are ratelimited or
    -- have reached max concurrency, so in that case we should not emit this.
    addBaseMarkerIfNeeded(markerKey, false)
    return {rcall("HGETALL", jobKey), jobId, 0, rateLimitedNextTtl or 0} -- get job data
end
--[[
  Promote a rate-limited group (if any) so that it is not rate limited anymore
]]
-- Includes
-- Includes
local function reinsertGroupIfNotMaxedOrPaused(prefixKey, groupId)
  if rcall("ZSCORE", prefixKey .. "groups:paused", groupId) == false then
    if not isGroupMaxed(prefixKey, groupId) then
      local groupsKey = prefixKey .. 'groups'
      local groupKey = prefixKey .. 'groups:' .. groupId
      return reinsertGroupIfNeeded(groupKey, groupsKey, groupId)
    end
  end
end
local function promoteRateLimitedGroups(prefixKey, markerKey, timestamp, paused)
    local groupsRateLimitKey = prefixKey .. 'groups:limit'
    local groupIds = rcall("ZPOPMIN", groupsRateLimitKey)
    if #groupIds > 0 then
        -- Is the group really limited?
        local groupRateLimitKey = prefixKey .. 'groups:' .. groupIds[1] ..
                                      ':limit'
        local jobCounter = tonumber(rcall("GET", groupRateLimitKey))
        local groupId = groupIds[1]
        if not jobCounter or jobCounter < 999999 then
            -- Group is not rate limited anymore so we promote it
            if reinsertGroupIfNotMaxedOrPaused(prefixKey, groupId) then
                addBaseMarkerIfNeeded(markerKey, paused)
                return 0, 0
            else
                return promoteRateLimitedGroups(prefixKey, markerKey, timestamp, paused)
            end
        else
            -- remove the key manually if ttl is zero to avoid side effects.
            local ttl = tonumber(rcall("PTTL", groupRateLimitKey))
            if ttl == 0 then rcall("DEL", groupRateLimitKey) end
            -- Group is still rate limited, re-add with new score
            local nextTimestamp = timestamp + ttl
            rcall("ZADD", groupsRateLimitKey, nextTimestamp, groupId)
            return nextTimestamp, ttl
        end
    end
    return 0, 0
end
-- TODO: parametrize KEYS
local function fetchNextJob(waitKey, activeKey, delayedKey,
                            rateLimiterKey, eventStreamKey, prefixKey, opts,
                            timestamp, markerKey, paused, maxJobs, KEYS,
                            rateLimitedNextTtl, checkDrained)
    -- Check if we move this call outside of the function so that it is only performed once per batch.
    if not rateLimitedNextTtl then
        -- TODO: add default value 0 in rateLimitedNextTtl
        rateLimitedNextTtl = promoteRateLimitedGroups(prefixKey, markerKey, timestamp, paused)
    end
    local jobId = rcall("RPOPLPUSH", waitKey, activeKey)
    -- If jobId is special ID 0:delay, then there is no job to process
    if jobId then
        if string.sub(jobId, 1, 2) == "0:" then
            rcall("LREM", activeKey, 1, jobId)
            jobId = rcall("RPOPLPUSH", waitKey, activeKey)
        end
    end
    if jobId then
        return prepareJobForProcessing(prefixKey, rateLimiterKey, eventStreamKey, jobId, timestamp,
            maxJobs, markerKey, opts, rateLimitedNextTtl)
    else
        jobId = moveJobFromPrioritizedToActive(KEYS[3], activeKey, KEYS[10], nil)
        if jobId then
            return prepareJobForProcessing(prefixKey, rateLimiterKey, eventStreamKey, jobId, timestamp,
                maxJobs, markerKey, opts, rateLimitedNextTtl)
        else
            local groupLimit
            local groupLimitDuration
            local groupMaxConcurrency
            if opts['group'] then
                if opts['group']['limit'] then
                    groupLimit = opts['group']['limit']['max']
                    groupLimitDuration = opts['group']['limit']['duration']
                end
                groupMaxConcurrency = opts['group']['concurrency']
            end
            jobId = moveJobToActiveFromGroup(prefixKey, activeKey, groupMaxConcurrency, groupLimit,
                                            groupLimitDuration, timestamp)
            if jobId then
                return prepareJobForProcessing(prefixKey, rateLimiterKey, eventStreamKey, jobId,
                                                timestamp, maxJobs, markerKey, opts, rateLimitedNextTtl)
            end
        end
    end
    -- Return the timestamp for the next delayed job if any.
    local nextTimestamp = getNextDelayedTimestamp(delayedKey)
    if nextTimestamp ~= nil then
        -- The result is guaranteed to be positive, since the
        -- ZRANGEBYSCORE command would have return a job otherwise.
        return {0, 0, 0, nextTimestamp}
    end
    if checkDrained then
        local waitLen = rcall("LLEN", waitKey)
        if waitLen == 0 then
            local activeLen = rcall("LLEN", activeKey)
            if activeLen == 0 then
                local prioritizedLen = rcall("ZCARD", KEYS[3])
                if prioritizedLen == 0 then
                    rcall("XADD", eventStreamKey, "*", "event", "drained")
                end
            end
        end
    end
    return {0, 0, 0, rateLimitedNextTtl or 0}
end
--[[
  Validate and move parent to active if needed.
]]
-- Includes
--[[
  Function to add job considering priority.
]]
-- Includes
local function addJobWithPriority(markerKey, prioritizedKey, priority, jobId,
    priorityCounterKey, isPausedOrMaxed, groupId)
  local prioCounter
  if groupId then
    prioCounter = rcall("HINCRBY", priorityCounterKey, groupId, 1)
  else
    prioCounter = rcall("INCR", priorityCounterKey)
  end
  local score = priority * 0x100000000 + prioCounter % 0x100000000
  rcall("ZADD", prioritizedKey, score, jobId)
  addBaseMarkerIfNeeded(markerKey, isPausedOrMaxed)
end
-- Includes
--[[
  Function to push back job considering priority in front of same prioritized jobs.
]]
local function pushBackJobWithPriority(prioritizedKey, priority, jobId)
  -- in order to put it at front of same prioritized jobs
  -- we consider prioritized counter as 0
  local score = priority * 0x100000000
  rcall("ZADD", prioritizedKey, score, jobId)
end
local function moveJobToTargetGroup(pushCmd, prefixKey, groupKey, groupId, jobId, markerKey, priority,
    isPaused, pushBack)
    if priority == 0 then
        addJobInTargetList(groupKey, markerKey, pushCmd, isPaused, jobId)
    elseif pushBack then
        pushBackJobWithPriority(groupKey .. ":p", priority, jobId)
    else
        addJobWithPriority(markerKey, groupKey .. ":p", priority, jobId,
            prefixKey .. "groups:pc", isPaused, groupId)
    end
end
local function addToGroup(lifo, prefixKey, groupId, jobId, markerKey, priority, isPaused, pushBack)
    local groupKey = prefixKey .. 'groups:' .. groupId
    local pushCmd = lifo and 'RPUSH' or 'LPUSH';
    --if group is paused we do not need to check for rate limit
    if rcall("ZSCORE", prefixKey .. 'groups:paused', groupId) ~= false then
        -- set isPaused as true in order to avoid adding marker
        moveJobToTargetGroup(pushCmd, prefixKey, groupKey, groupId, jobId, markerKey, priority, true, pushBack)
    else
        -- Has this group reached maximum concurrency?
        local hasReachedMaxConcurrency = rcall("ZSCORE", prefixKey .. 'groups:max', groupId) ~= false
        -- Is group rate limited?
        local groupRateLimitKey = groupKey .. ':limit'
        local jobCounter = tonumber(rcall("GET", groupRateLimitKey))
        local isRateLimited = jobCounter and jobCounter >= 999999
        if hasReachedMaxConcurrency or isRateLimited then
            -- set isPaused as true in order to avoid adding marker
            moveJobToTargetGroup(pushCmd, prefixKey, groupKey, groupId, jobId, markerKey, priority, true, pushBack)
        else
            moveJobToTargetGroup(pushCmd, prefixKey, groupKey, groupId, jobId, markerKey, priority, isPaused, pushBack)
            local groupsKey = prefixKey .. 'groups'
            local highscore = rcall("ZREVRANGE", groupsKey, 0, 0,
                "withscores")[2] or 0
            rcall("ZADD", groupsKey, highscore + 1, groupId)
        end
    end
end
local function moveParentToWaitIfNeeded(parentQueueKey, parentDependenciesKey, parentKey, parentId, timestamp)
  local isParentActive = rcall("ZSCORE", parentQueueKey .. ":waiting-children", parentId)
  if rcall("SCARD", parentDependenciesKey) == 0 and isParentActive then 
    rcall("ZREM", parentQueueKey .. ":waiting-children", parentId)
    local parentWaitKey = parentQueueKey .. ":wait"
    local parentPausedKey = parentQueueKey .. ":paused"
    local parentActiveKey = parentQueueKey .. ":active"
    local parentMetaKey = parentQueueKey .. ":meta"
    local parentMarkerKey = parentQueueKey .. ":marker"
    local jobAttributes = rcall("HMGET", parentKey, "priority", "delay", "gid")
    local priority = tonumber(jobAttributes[1]) or 0
    local delay = tonumber(jobAttributes[2]) or 0
    if delay > 0 then
      local delayedTimestamp = tonumber(timestamp) + delay 
      local score = delayedTimestamp * 0x1000
      local parentDelayedKey = parentQueueKey .. ":delayed" 
      rcall("ZADD", parentDelayedKey, score, parentId)
      rcall("XADD", parentQueueKey .. ":events", "*", "event", "delayed", "jobId", parentId,
        "delay", delayedTimestamp)
      addDelayMarkerIfNeeded(parentMarkerKey, parentDelayedKey)
    elseif jobAttributes[3] then
      local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
      addToGroup(true, parentQueueKey .. ":", jobAttributes[3], parentId, parentMarkerKey, priority,
        isPausedOrMaxed, false)
      rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting", "jobId", parentId, "prev",
        "waiting-children")  
    else
      if priority == 0 then
        local parentTarget, isParentPausedOrMaxed = getTargetQueueList(parentMetaKey, parentActiveKey,
          parentWaitKey, parentPausedKey)
        addJobInTargetList(parentTarget, parentMarkerKey, "RPUSH", isParentPausedOrMaxed, parentId)
      else
        local isPausedOrMaxed = isQueuePausedOrMaxed(parentMetaKey, parentActiveKey)
        addJobWithPriority(parentMarkerKey, parentQueueKey .. ":prioritized", priority, parentId,
          parentQueueKey .. ":pc", isPausedOrMaxed, nil)
      end
      rcall("XADD", parentQueueKey .. ":events", "*", "event", "waiting", "jobId", parentId,
        "prev", "waiting-children")
    end
  end
end
--[[
  Updates the delay set, by moving delayed jobs that should
  be processed now to "wait".
    Events:
      'waiting'
]]
-- Includes
-- Try to get as much as 1000 jobs at once, and returns the nextTimestamp if
-- there are more delayed jobs to process.
local function promoteDelayedJobs(delayedKey, markerKey, targetKey, prioritizedKey,
                                  eventStreamKey, prefix, timestamp, priorityCounterKey, paused)
    local jobs = rcall("ZRANGEBYSCORE", delayedKey, 0, (timestamp + 1) * 0x1000 - 1, "LIMIT", 0, 1000)
    if (#jobs > 0) then
        rcall("ZREM", delayedKey, unpack(jobs))
        for _, jobId in ipairs(jobs) do
            local jobKey = prefix .. jobId
            local jobAttributes = rcall("HMGET", jobKey, "priority", "gid")
            local priority = tonumber(jobAttributes[1]) or 0
            -- Standard or priority add
            if jobAttributes[2] then
                addToGroup(false, prefix, jobAttributes[2], jobId, markerKey,
                    priority, paused, false)
            elseif priority == 0 then
                -- LIFO or FIFO
                addJobInTargetList(targetKey, markerKey, "LPUSH", paused, jobId)
            else
                addJobWithPriority(markerKey, prioritizedKey, priority,
                  jobId, priorityCounterKey, paused, nil)
            end
            -- Emit waiting event
            rcall("XADD", eventStreamKey, "*", "event", "waiting", "jobId",
                  jobId, "prev", "delayed")
            rcall("HSET", jobKey, "delay", 0)
        end
    end
end
--[[
  Validate and move or add dependencies to parent.
]]
-- Includes
local function updateParentDepsIfNeeded(parentKey, parentQueueKey, parentDependenciesKey,
  parentId, jobIdKey, returnvalue, timestamp )
  local processedSet = parentKey .. ":processed"
  rcall("HSET", processedSet, jobIdKey, returnvalue)
  moveParentToWaitIfNeeded(parentQueueKey, parentDependenciesKey, parentKey, parentId,
    timestamp)
end
if rcall("EXISTS", jobIdKey) == 1 then -- // Make sure job exists
    local markerKey = KEYS[14]
    local opts = cmsgpack.unpack(ARGV[8])
    local token = opts['token']
    local errorCode = removeLock(jobIdKey, KEYS[5], token, ARGV[1])
    if errorCode < 0 then
        return errorCode
    end
    updateJobFields(jobIdKey, ARGV[9]);
    local lockDuration = opts['lockDuration']
    local attempts = opts['attempts']
    local maxMetricsSize = opts['maxMetricsSize']
    if rcall("SCARD", jobIdKey .. ":dependencies") ~= 0 then -- // Make sure it does not have pending dependencies
        return -4
    end
    local jobAttributes = rcall("HMGET", jobIdKey, "parentKey", "parent", "deid")
    local parentKey = jobAttributes[1] or ""
    local parentId = ""
    local parentQueueKey = ""
    if jobAttributes[2] ~= false then
        local jsonDecodedParent = cjson.decode(jobAttributes[2])
        parentId = jsonDecodedParent['id']
        parentQueueKey = jsonDecodedParent['queueKey']
    end
    local jobId = ARGV[1]
    local timestamp = ARGV[2]
    -- Remove from active list (if not active we shall return error)
    local numRemovedElements = rcall("LREM", activeKey, -1, jobId)
    if (numRemovedElements < 1) then
        return -3
    end
    local target, isPausedOrMaxed = getTargetQueueList(metaKey, activeKey, waitKey, KEYS[8])
    -- Trim events before emiting them to avoid trimming events emitted in this script
    trimEvents(metaKey, eventStreamKey)
    removeDeduplicationKeyIfNeeded(prefixKey, jobAttributes[3])
    -- Update the active group count and set.
    local jobKey = prefixKey .. jobId
    local groupId = rcall("HGET", jobKey, "gid")
    if groupId then
        local maxConcurrency = opts['group'] and opts['group']['concurrency']
        decreaseGroupConcurrency(prefixKey, markerKey, isPausedOrMaxed, groupId, maxConcurrency or 999999)
    end
    -- If job has a parent we need to 
    -- 1) remove this job id from parents dependencies
    -- 2) move the job Id to parent "processed" set
    -- 3) push the results into parent "results" list
    -- 4) if parent's dependencies is empty, then move parent to "wait/paused". Note it may be a different queue!.
    -- NOTE: Priorities not supported yet for parent jobs.
    -- local parentQueueKey = ARGV[13]
    if parentId == "" and parentKey ~= "" then
        parentId = getJobIdFromKey(parentKey)
        parentQueueKey = getJobKeyPrefix(parentKey, ":" .. parentId)
    end
    if parentId ~= "" then
        if ARGV[5] == "completed" then
            local dependenciesSet = parentKey .. ":dependencies"
            if rcall("SREM", dependenciesSet, jobIdKey) == 1 then
                updateParentDepsIfNeeded(parentKey, parentQueueKey, dependenciesSet, parentId, jobIdKey, ARGV[4],
                    timestamp)
            end
        else
            if opts['fpof'] then
                moveParentFromWaitingChildrenToFailed(parentQueueKey, parentKey, parentId, jobIdKey, timestamp)
            elseif opts['idof'] or opts['rdof'] then
                local dependenciesSet = parentKey .. ":dependencies"
                if rcall("SREM", dependenciesSet, jobIdKey) == 1 then
                    moveParentToWaitIfNeeded(parentQueueKey, dependenciesSet, parentKey, parentId, timestamp)
                    if opts['idof'] then
                        local failedSet = parentKey .. ":failed"
                        rcall("HSET", failedSet, jobIdKey, ARGV[4])
                    end
                end
            end
        end
    end
    -- Remove job?
    local maxCount = opts['keepJobs']['count']
    local maxAge = opts['keepJobs']['age']
    local attemptsMade = rcall("HINCRBY", jobIdKey, "atm", 1)
    if maxCount ~= 0 then
        -- Add to complete/failed set
        rcall("ZADD", finishedKey, timestamp, jobId)
        rcall("HMSET", jobIdKey, ARGV[3], ARGV[4], "finishedOn", timestamp)
        -- "returnvalue" / "failedReason" and "finishedOn"
        -- Remove old jobs?
        if maxAge ~= nil then
            removeJobsByMaxAge(timestamp, maxAge, finishedKey, prefixKey)
        end
        if maxCount ~= nil and maxCount > 0 then
            removeJobsByMaxCount(maxCount, finishedKey, prefixKey)
        end
    else
        removeJobKeys(jobIdKey)
        if parentKey ~= "" then
            removeParentDependencyKey(jobIdKey, false, parentKey, jobAttributes[3])
        end
    end
    rcall("XADD", eventStreamKey, "*", "event", ARGV[5], "jobId", jobId, ARGV[3], ARGV[4])
    if ARGV[5] == "failed" then
        if tonumber(attemptsMade) >= tonumber(attempts) then
            rcall("XADD", eventStreamKey, "*", "event", "retries-exhausted", "jobId", jobId, "attemptsMade",
                attemptsMade)
        end
    end
    -- Collect metrics
    if maxMetricsSize ~= "" then
        collectMetrics(KEYS[13], KEYS[13] .. ':data', maxMetricsSize, timestamp)
    end
    local rateLimitedNextTtl = promoteRateLimitedGroups(prefixKey, markerKey, timestamp, isPausedOrMaxed)
    -- Try to get next job to avoid an extra roundtrip if the queue is not closing,
    -- and not rate limited and not paused!
    if (ARGV[6] == "1" and not isPausedOrMaxed) then
        local delayedKey = KEYS[7]
        -- Check if there are delayed jobs that can be promoted
        promoteDelayedJobs(delayedKey, markerKey, target, prioritizedKey, KEYS[4], prefixKey, timestamp, KEYS[10],
                          isPausedOrMaxed)
        local rateLimiterKey = KEYS[6]
        local streamEventsKey = KEYS[4]
        local maxJobs = tonumber(opts['limiter'] and opts['limiter']['max'])
        local expireTime = getRateLimitTTL(maxJobs, rateLimiterKey)
        if expireTime > 0 then
            return {0, 0, expireTime, 0}
        end
        return fetchNextJob(waitKey, activeKey, delayedKey, rateLimiterKey, streamEventsKey, prefixKey, opts, timestamp,
            markerKey, isPausedOrMaxed, maxJobs, KEYS, rateLimitedNextTtl, true)
    end
    return {0, 0, 0, rateLimitedNextTtl or 0}
else
    return -1
end
`;
export const moveToFinished = {
    name: 'moveToFinished',
    content,
    keys: 14,
};
//# sourceMappingURL=moveToFinished-14.js.map